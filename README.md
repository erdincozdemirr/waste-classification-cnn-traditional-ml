# â™»ï¸ Waste Classification with CNN & Traditional Machine Learning

This project focuses on **image-based waste classification** by comparing **deep learning** and **traditional machine learning** approaches.

The study includes:
- An **end-to-end CNN model (AlexNet)** trained directly on images
- **Traditional ML models (SVM, Random Forest, XGBoost)** trained on **MobileNet-extracted features**
- A detailed experimental pipeline with **confusion matrices, ROC curves, and multiple performance metrics**

Developed as part of an **MSc Machine Learning course**.

---

## ğŸ“Œ Project Motivation

Waste classification is an important problem in recycling and environmental sustainability.  
This project aims to explore:

- How well a CNN (AlexNet) performs on raw images
- How traditional ML models perform when combined with deep feature extraction
- The trade-offs between **end-to-end deep learning** and **feature-based ML pipelines**

---

## ğŸ§  Models Used

### Deep Learning
- **AlexNet (PyTorch)**
  - Trained from scratch (no pretrained weights)
  - Focal Loss + Label Smoothing
  - Early Stopping & LR Scheduler
  - Multiple hyperparameter configurations (ALEX1â€“ALEX4)

### Feature Extraction
- **MobileNet**
  - Used as a fixed feature extractor
  - Generates embeddings for traditional ML models

### Traditional Machine Learning
- Support Vector Machine (SVM)
- Random Forest Classifier
- XGBoost Classifier

---

## ğŸ“‚ Project Structure

waste-classification/
â”‚
â”œâ”€â”€ CNN/
â”‚ â”œâ”€â”€ main_2_alexNet.py # AlexNet training pipeline (ALEX1â€“ALEX4)
â”‚ â”œâ”€â”€ Outputs/ # Saved AlexNet models (.pth)
â”‚ â””â”€â”€ Models/
â”‚ â””â”€â”€ alexnet_overrided.py # Custom AlexNet implementation
â”‚
â”œâ”€â”€ Traditional/
â”‚ â”œâ”€â”€ Model/ # SVM / RF / XGBoost (.pkl)
â”‚ â””â”€â”€ Results/ # Traditional ML results
â”‚
â”œâ”€â”€ Results/
â”‚ â””â”€â”€ ALEX/
â”‚ â”œâ”€â”€ ALEX1/
â”‚ â”œâ”€â”€ ALEX2/
â”‚ â”œâ”€â”€ ALEX3/
â”‚ â”œâ”€â”€ ALEX4/
â”‚ â””â”€â”€ ...
â”‚
â”œâ”€â”€ lib/
â”‚ â”œâ”€â”€ dataset_precreator.py
â”‚ â”œâ”€â”€ generic_image_dataset.py
â”‚ â”œâ”€â”€ feature_extractor.py # MobileNet feature extractor
â”‚ â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ Datasets/ # Waste images
â”œâ”€â”€ try.py # Inference script (CNN + ML comparison)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Kodu kopyala

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Create virtual environment
```bash
python -m venv .venv
Activate:

bash
Kodu kopyala
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # macOS / Linux
2ï¸âƒ£ Install dependencies
bash
Kodu kopyala
pip install -r requirements.txt
ğŸš€ Running the Project
ğŸ”¹ Train AlexNet (4 configurations)
bash
Kodu kopyala
python CNN/main_2_alexNet.py
This will:

Train ALEX1â€“ALEX4

Save models to:

swift
Kodu kopyala
CNN/Outputs/ALEX1.pth
CNN/Outputs/ALEX2.pth
CNN/Outputs/ALEX3.pth
CNN/Outputs/ALEX4.pth
Save metrics, confusion matrices and ROC curves to:

swift
Kodu kopyala
Results/ALEX/ALEX1/
Results/ALEX/ALEX2/
Results/ALEX/ALEX3/
Results/ALEX/ALEX4/
Write the best model summary to:

swift
Kodu kopyala
Results/ALEX/BEST_MODEL.txt
ğŸ”¹ Run inference & model comparison
bash
Kodu kopyala
python try.py
This script:

Loads a test image

Runs prediction using:

AlexNet (.pth)

SVM

Random Forest

XGBoost

Displays predictions together on the same image

ğŸ“Š Evaluation Metrics
The following metrics are computed for train / validation / test sets:

Accuracy

F1 Score

Sensitivity (Recall)

Specificity

ROC-AUC

Confusion Matrix

ROC Curves (per class)

All results are saved as .txt and .png files for reproducibility.

ğŸ† Model Selection
Models are ranked based on validation accuracy

The best-performing AlexNet configuration is recorded in:

swift
Kodu kopyala
Results/ALEX/BEST_MODEL.txt
ğŸ§ª Key Takeaways
AlexNet provides strong end-to-end performance on raw images

MobileNet + traditional ML offers a competitive and efficient alternative

Feature-based ML pipelines are easier to train and faster to iterate

CNNs capture spatial patterns more effectively but require longer training

ğŸ§° Technologies Used
Python

PyTorch & Torchvision

Scikit-learn

XGBoost

NumPy, SciPy

Matplotlib, Seaborn

OpenCV, Pillow

ğŸ‘¨â€ğŸ“ Academic Context
This project was developed as part of an MSc-level Machine Learning course, focusing on:

Model comparison

Experimental rigor

Reproducibility

Performance analysis
